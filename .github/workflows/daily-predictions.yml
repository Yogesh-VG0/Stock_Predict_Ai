name: Daily ML Predictions

on:
  schedule:
    # Mon-Fri. Use a buffer after close (covers EST/EDT better than 21:30 UTC)
    - cron: "15 22 * * 1-5"
  workflow_dispatch:

concurrency:
  group: daily-ml-predictions
  cancel-in-progress: false

env:
  MONGODB_URI: ${{ secrets.MONGODB_URI }}

jobs:
  update-predictions:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        batch:
          - "AAPL MSFT GOOGL AMZN TSLA"
          - "NVDA META NFLX JPM V"
          - "JNJ WMT PG UNH HD"
          - "MA BAC XOM LLY ABBV"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: ml_backend/requirements-prod.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ml_backend/requirements-prod.txt

      - name: Run ML Pipeline (batch)
        env:
          MONGODB_URI: ${{ secrets.MONGODB_URI }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
          FMP_API_KEY: ${{ secrets.FMP_API_KEY }}
          ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}
          MARKETAUX_API_KEY: ${{ secrets.MARKETAUX_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: "StockPredictAI/1.0"
          PYTHONPATH: ${{ github.workspace }}
          BATCH_TICKERS: ${{ matrix.batch }}
          GITHUB_SHA: ${{ github.sha }}
          RUN_ID: ${{ github.run_id }}
        run: |
          set -e
          echo "Batch tickers: $BATCH_TICKERS"

          # Simple retry loop (3 tries)
          for i in 1 2 3; do
            echo "Attempt $i..."
            python -m ml_backend.scripts.run_pipeline --tickers $BATCH_TICKERS && break
            if [ "$i" -eq 3 ]; then
              echo "Pipeline failed after 3 attempts."
              exit 1
            fi
            sleep $((i * 30))
          done

      - name: Verify predictions are fresh (per ticker)
        env:
          MONGODB_URI: ${{ secrets.MONGODB_URI }}
          BATCH_TICKERS: ${{ matrix.batch }}
        run: |
          python - << 'PY'
          import os
          from datetime import datetime, timedelta, timezone
          from pymongo import MongoClient

          uri = os.getenv("MONGODB_URI")
          tickers = os.getenv("BATCH_TICKERS","").split()
          if not uri or not tickers:
            raise SystemExit("Missing MONGODB_URI or tickers")

          client = MongoClient(uri, serverSelectionTimeoutMS=8000, connectTimeoutMS=8000)
          client.admin.command("ping")
          db = client["stock_predictor"]
          col = db["stock_predictions"]

          now = datetime.now(timezone.utc)
          cutoff = now - timedelta(hours=3)

          # Require at least one doc per ticker per horizon, excluding _meta
          horizons = ["next_day", "7_day", "30_day"]

          missing = []
          stale = []

          for t in tickers:
            for w in horizons:
              q = {
                "ticker": t,
                "window": {"$eq": w},   # excludes _meta rows
              }
              doc = col.find_one(q, sort=[("timestamp",-1)])
              if not doc:
                missing.append((t,w))
                continue
              ts = doc.get("timestamp")
              if not ts or ts < cutoff:
                stale.append((t,w,ts))

          print(f"Checked {len(tickers)} tickers x {len(horizons)} horizons")
          if missing:
            print("Missing:", missing)
          if stale:
            print("Stale:", stale)

          assert not missing, f"Missing predictions: {missing}"
          assert not stale, f"Stale predictions (older than 6h): {stale}"
          print("Fresh predictions verified for this batch")
          PY

      - name: Upload logs/artifacts (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_id }}-${{ strategy.job-index }}
          path: |
            ml_backend/**/*.log
            **/*.log
          if-no-files-found: ignore
